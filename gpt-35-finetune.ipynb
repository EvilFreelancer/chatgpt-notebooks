{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ChatGPT-3.5 fine-tuning\n",
    "\n",
    "This notebook contains code for fine-tuning the ChatGPT-3.5 Turbo model on the [RecipeNLG dataset](https://recipenlg.cs.put.poznan.pl/dataset). It is based on [OpenAI's fine-tuning example](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates).\n",
    "\n",
    "Our goal is to adapt the ChatGPT-3.5 Turbo to extract ingredients from recipe descriptions and return them in the form of a JSON array containing strings. Essentially, we're creating a model for data summarization from detailed recipe content.\n",
    "\n",
    "It is assumed that you have already downloaded the RecipeNLG dataset. If not, please do it now and place it into the root of this project.\n",
    "\n",
    "## 1. Dataset\n",
    "\n",
    "First, we need to prepare environment and the dataset for fine-tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "556aa05853a5b227"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import openai\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "\n",
    "# Skip this step if archive with dataset was already unpacked\n",
    "full_dataset = \"./dataset/full_dataset.csv\"  #@param {type:\"string\"}\n",
    "dataset_archive = \"./dataset.zip\"  #@param {type:\"string\"}\n",
    "if not os.path.exists(full_dataset):\n",
    "    if os.path.exists(dataset_archive):\n",
    "        with zipfile.ZipFile(dataset_archive, 'r') as zip_ref: zip_ref.extractall(\".\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:47:53.699039665Z",
     "start_time": "2023-08-24T02:47:53.690633242Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     1000\n",
      "title          1000\n",
      "ingredients    1000\n",
      "directions     1000\n",
      "link           1000\n",
      "source         1000\n",
      "NER            1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now let's extract 1k random lines from original dataset and save them to dataset_1k.csv file\n",
    "dataset_1k = \"./dataset/dataset_1k.csv\"  #@param {type:\"string\"}\n",
    "if not os.path.exists(dataset_1k):\n",
    "    df = pd.read_csv(full_dataset)\n",
    "    sample_df = df.sample(\n",
    "        n=1000,  #@param {type:\"integer\"}\n",
    "        random_state=42  #@param {type:\"integer\"}\n",
    "    )\n",
    "    sample_df.to_csv(dataset_1k, index=False)\n",
    "else:\n",
    "    sample_df = pd.read_csv(dataset_1k)\n",
    "\n",
    "# Let's print counts\n",
    "pprint(sample_df.count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:47:53.743037344Z",
     "start_time": "2023-08-24T02:47:53.694351903Z"
    }
   },
   "id": "cf243b3ab9c9b8ba"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'You are a helpful recipe assistant. You are to '\n",
      "                          'extract the generic ingredients from each of the '\n",
      "                          'recipes provided.',\n",
      "               'role': 'system'},\n",
      "              {'content': 'Title: Marinated Flank Steak Recipe\\n'\n",
      "                          '\\n'\n",
      "                          'Ingredients: [\"1 1/2 pound flank steak\", \"1/2 c. '\n",
      "                          'finely minced green onions (scallions)\", \"1/2 c. '\n",
      "                          'dry red wine\", \"1/4 c. soy sauce\", \"3 tbsp. salad '\n",
      "                          'oil\", \"3 teaspoon sesame seeds\", \"2 teaspoon packed '\n",
      "                          'brown sugar\", \"1/4 teaspoon grnd black pepper\", '\n",
      "                          '\"1/4 teaspoon grnd ginger\", \"1 clove garlic, '\n",
      "                          'chopped\"]\\n'\n",
      "                          '\\n'\n",
      "                          'Generic ingredients: ',\n",
      "               'role': 'user'},\n",
      "              {'content': '[\"flank steak\", \"green onions\", \"red wine\", \"soy '\n",
      "                          'sauce\", \"salad oil\", \"sesame seeds\", \"brown sugar\", '\n",
      "                          '\"grnd black pepper\", \"grnd ginger\", \"clove garlic\"]',\n",
      "               'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "# Now let's prepare system prompt and method for converting receipt description into a valid ChatGPT-3.5 conversation.\n",
    "system_message = \"You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.\"  #@param {type:\"string\"}\n",
    "\n",
    "# Function for preparing example conversation\n",
    "def prepare_example_conversation(row):\n",
    "    user_message = f\"\"\"Title: {row['title']}\\n\\nIngredients: {row['ingredients']}\\n\\nGeneric ingredients: \"\"\"\n",
    "    # Let's prepare conversation messages\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_message})  # here is the system prompt\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})  # this message will contain recipe title and ingredients\n",
    "    messages.append({\"role\": \"assistant\", \"content\": row[\"NER\"]})  # this message will contain array extracted ingredients\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "# Print a single example of function work\n",
    "pprint(prepare_example_conversation(sample_df.iloc[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:47:53.743244774Z",
     "start_time": "2023-08-24T02:47:53.735899666Z"
    }
   },
   "id": "a5d355212e645a9f"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}, {'role': 'user', 'content': 'Title: Marinated Flank Steak Recipe\\n\\nIngredients: [\"1 1/2 pound flank steak\", \"1/2 c. finely minced green onions (scallions)\", \"1/2 c. dry red wine\", \"1/4 c. soy sauce\", \"3 tbsp. salad oil\", \"3 teaspoon sesame seeds\", \"2 teaspoon packed brown sugar\", \"1/4 teaspoon grnd black pepper\", \"1/4 teaspoon grnd ginger\", \"1 clove garlic, chopped\"]\\n\\nGeneric ingredients: '}, {'role': 'assistant', 'content': '[\"flank steak\", \"green onions\", \"red wine\", \"soy sauce\", \"salad oil\", \"sesame seeds\", \"brown sugar\", \"grnd black pepper\", \"grnd ginger\", \"clove garlic\"]'}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}, {'role': 'user', 'content': 'Title: French Chicken Stew\\n\\nIngredients: [\"1 tablespoon rosemary\", \"1 teaspoon thyme\", \"3 bay leaves\", \"1 teaspoon smoked paprika\", \"1 teaspoon pepper\", \"1/4 cup red wine\", \"3 cups chicken broth\", \"2 cups button mushrooms sliced\", \"2 cups mushroom mix, oyster, shiitake, baby bella, sliced\", \"2 medium carrots sliced diagonally\", \"1 onion medium, chopped\", \"1 red potato medium, cut in 1-inch pieces\", \"1 cup frozen green beans 1-inch pieces\", \"1/2 can black olives pitted ripe, halved\", \"1 handful grape tomatoes halved\", \"8 chicken thighs with bones and skin. 2-3 lbs\", \"2 stalks celery\", \"3 cups water\"]\\n\\nGeneric ingredients: '}, {'role': 'assistant', 'content': '[\"rosemary\", \"thyme\", \"bay leaves\", \"paprika\", \"pepper\", \"red wine\", \"chicken broth\", \"button mushrooms\", \"mushroom mix\", \"carrots\", \"onion\", \"frozen green beans\", \"black olives\", \"handful grape tomatoes\", \"chicken\", \"stalks celery\", \"water\"]'}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}, {'role': 'user', 'content': 'Title: Glazed Carrots\\n\\nIngredients: [\"3 to 4 carrots\", \"1 1/2 Tbsp. butter\", \"1/3 c. brown sugar\", \"grated lemon rind and juice\"]\\n\\nGeneric ingredients: '}, {'role': 'assistant', 'content': '[\"carrots\", \"butter\", \"brown sugar\", \"lemon rind\"]'}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}, {'role': 'user', 'content': 'Title: Moms Pie Dough \\n\\nIngredients: [\"4.5 Cups Flour\", \"1.5 Tsp Salt\", \"Pinch Baking Powder\", \"1 Tbls Sugar\", \"1 2/3 cup Crisco\", \"1 egg lightly beaten\", \"1 tsp vinegar\", \"Ice Water\"]\\n\\nGeneric ingredients: '}, {'role': 'assistant', 'content': '[\"Flour\", \"Salt\", \"Baking Powder\", \"Sugar\", \"Crisco\", \"egg\", \"vinegar\", \"Water\"]'}]}\n",
      "{'messages': [{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}, {'role': 'user', 'content': 'Title: Pretzel Salad Or Dessert\\n\\nIngredients: [\"2 c. crushed small thin pretzels (sticks)\", \"3/4 c. margarine\"]\\n\\nGeneric ingredients: '}, {'role': 'assistant', 'content': '[\"thin pretzels\", \"margarine\"]'}]}\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset using prepare_example_conversation function to each row\n",
    "sample_dataset = sample_df.apply(prepare_example_conversation, axis=1).tolist()\n",
    "\n",
    "# Let's print few prepared examples\n",
    "for example in sample_dataset[:5]:\n",
    "    print(example)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:47:53.743423620Z",
     "start_time": "2023-08-24T02:47:53.736111744Z"
    }
   },
   "id": "dd7127150a4541a4"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 300\n"
     ]
    }
   ],
   "source": [
    "# Now let's split dataset to training and validation sets\n",
    "train_size = int(0.7 * len(sample_dataset))  #@param {type:\"integer\"}\n",
    "train_dataset = sample_dataset[:train_size]  # 70% for training\n",
    "val_dataset = sample_dataset[train_size:]  # 30% for validation\n",
    "\n",
    "# Counts\n",
    "print(len(train_dataset), len(val_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:47:53.743568132Z",
     "start_time": "2023-08-24T02:47:53.736254924Z"
    }
   },
   "id": "222340b4293322d4"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "training_file_name = \"train_dataset.jsonl\"  #@param {type:\"string\"}\n",
    "with open(training_file_name, \"w\") as file:\n",
    "    for entry in train_dataset: file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "validation_file_name = \"val_dataset.jsonl\"  #@param {type:\"string\"}\n",
    "with open(\"val_dataset.jsonl\", \"w\") as file:\n",
    "    for entry in val_dataset: file.write(json.dumps(entry) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:47:53.743670765Z",
     "start_time": "2023-08-24T02:47:53.736609500Z"
    }
   },
   "id": "cc2ef93c0ece7616"
  },
  {
   "cell_type": "markdown",
   "source": [
    "On the next step we will make calls to OpenAI API. To do that we need to install OpenAI Python library and set up API key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "403805c8b7a2882c"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OpenAIObject text_completion id=cmpl-7quhc8Y4g0rodWeJBXKDafTBY8Dbd at 0x7fef98b41850> JSON: {\n",
      "  \"id\": \"cmpl-7quhc8Y4g0rodWeJBXKDafTBY8Dbd\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1692845376,\n",
      "  \"model\": \"davinci\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \" ind Brazil. Tap-\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 3,\n",
      "    \"completion_tokens\": 5,\n",
      "    \"total_tokens\": 8\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now let's change OpenAI API key to yours\n",
    "OPENAI_API_KEY = getpass.getpass(prompt=\"OPENAI_API_KEY:\")  #@param {type:\"string\"}\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", OPENAI_API_KEY)\n",
    "\n",
    "# Let's check if it works\n",
    "response = openai.Completion.create(engine=\"davinci\", prompt=\"Hello, world\", max_tokens=5)\n",
    "pprint(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T02:49:36.832826756Z",
     "start_time": "2023-08-24T02:49:33.142605279Z"
    }
   },
   "id": "c01fa516208eb7aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Uploading dataset to OpenAI\n",
    "\n",
    "On this step we will upload dataset to OpenAI API."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e85da29f03ee2"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-XG4instzfClDqqvsmut5TE0y\n",
      "Validation file ID: file-G4ALF7HDzbWjIsAJayqn92kd\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]  # this is the ID we'll use to start fine-tuning job\n",
    "\n",
    "# Validation dataset\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]  # this is the ID we'll use to start fine-tuning job\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T03:04:16.575786036Z",
     "start_time": "2023-08-24T03:04:12.801451160Z"
    }
   },
   "id": "bd3ba75ba11e75e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Creating fine-tuning job\n",
    "\n",
    "On this step we will create fine-tuning job using previously uploaded dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9db12d6e30267b72"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-HSpCc9iVymosVDwmRn3p3hlB\n",
      "Status: created\n"
     ]
    }
   ],
   "source": [
    "# Create fine-tuning job\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",  #@param {type:\"string\"}\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]  # this is the ID we'll use to monitor the status of the fine-tuning job\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T03:13:56.116009129Z",
     "start_time": "2023-08-24T03:13:54.983600823Z"
    }
   },
   "id": "6600def63887d97f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Monitoring fine-tuning job\n",
    "\n",
    "This step will take a while. You can check the status of the fine-tuning job by running the following cell."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "598c64a2b5b9b8a1"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-HSpCc9iVymosVDwmRn3p3hlB\n",
      "Status: running\n",
      "Trained Tokens: None\n",
      "Fine-tuned model ID: None\n"
     ]
    }
   ],
   "source": [
    "# Check fine-tuning job status\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(\"Trained Tokens:\", response[\"trained_tokens\"])\n",
    "print(\"Fine-tuned model ID:\", response[\"fine_tuned_model\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T03:14:06.442960866Z",
     "start_time": "2023-08-24T03:14:06.167270937Z"
    }
   },
   "id": "370d0b37500e1d75"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tune: ftjob-HSpCc9iVymosVDwmRn3p3hlB\n",
      "Fine tuning job started\n",
      "Fine tuning job failed, re-enqueued for retry\n",
      "Fine tuning job started\n",
      "Step 100/2100: training loss=0.32\n",
      "Step 200/2100: training loss=0.77\n",
      "Step 300/2100: training loss=0.08\n",
      "Step 400/2100: training loss=0.05\n",
      "Step 500/2100: training loss=0.23\n",
      "Step 600/2100: training loss=0.29\n",
      "Step 700/2100: training loss=0.05\n",
      "Step 800/2100: training loss=0.00\n",
      "Step 900/2100: training loss=0.34\n",
      "Step 1000/2100: training loss=1.13\n",
      "Step 1100/2100: training loss=0.00\n",
      "Step 1200/2100: training loss=0.41\n",
      "Step 1300/2100: training loss=0.35\n",
      "Step 1400/2100: training loss=0.04\n",
      "Step 1500/2100: training loss=0.00\n",
      "Step 1600/2100: training loss=0.38\n",
      "Step 1700/2100: training loss=0.15\n",
      "Step 1800/2100: training loss=0.00\n",
      "Step 1900/2100: training loss=0.00\n",
      "Step 2000/2100: training loss=0.10\n",
      "Step 2100/2100: training loss=0.00\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal::7qwbrgm8\n",
      "Fine-tuning job successfully completed\n"
     ]
    }
   ],
   "source": [
    "# Check fine-tuning job events\n",
    "response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n",
    "\n",
    "events = response[\"data\"]\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event[\"message\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T08:29:06.133214908Z",
     "start_time": "2023-08-24T08:29:05.675163220Z"
    }
   },
   "id": "47e06e0d3224f985"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-HSpCc9iVymosVDwmRn3p3hlB\n",
      "Status: succeeded\n",
      "Trained Tokens: 346584\n",
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0613:personal::7qwbrgm8\n"
     ]
    }
   ],
   "source": [
    "# Check fine-tuning job status\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(\"Trained Tokens:\", response[\"trained_tokens\"])\n",
    "print(\"Fine-tuned model ID:\", response[\"fine_tuned_model\"])\n",
    "\n",
    "fine_tuned_model_id = response[\"fine_tuned_model\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T08:59:05.748590139Z",
     "start_time": "2023-08-24T08:59:05.280275484Z"
    }
   },
   "id": "3438d5c6eb8fe209"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Model inference\n",
    "\n",
    "On this step we will use fine-tuned model to extract ingredients from recipe descriptions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59c40aec683fe24e"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful recipe assistant. You are to extract the '\n",
      "             'generic ingredients from each of the recipes provided.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Title: 7 Layer Salad\\n'\n",
      "             '\\n'\n",
      "             \"Ingredients: ['10 to 12 leaves spinach, torn up', '8 to 10 \"\n",
      "             \"mushrooms, sliced', 'Bermuda onion, sliced', '2 boiled eggs, \"\n",
      "             \"sliced', '4 strips bacon, fried and crumbled', 'tomatoes, peeled \"\n",
      "             \"and chunked', 'Ranch dressing']\\n\"\n",
      "             '\\n'\n",
      "             'Generic ingredients: ',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "test_df = [\n",
    "    {\n",
    "        \"id\": 9999,\n",
    "        \"title\": \"7 Layer Salad\",\n",
    "        \"ingredients\": [\n",
    "            \"10 to 12 leaves spinach, torn up\",\n",
    "            \"8 to 10 mushrooms, sliced\",\n",
    "            \"Bermuda onion, sliced\",\n",
    "            \"2 boiled eggs, sliced\",\n",
    "            \"4 strips bacon, fried and crumbled\",\n",
    "            \"tomatoes, peeled and chunked\",\n",
    "            \"Ranch dressing\"\n",
    "        ],\n",
    "        # \"NER\": [\"spinach\", \"mushrooms\", \"Bermuda onion\", \"eggs\", \"bacon\", \"tomatoes\", \"dressing\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Need to prepare system prompt and user message\n",
    "user_message = f\"\"\"Title: {test_df[0]['title']}\\n\\nIngredients: {test_df[0]['ingredients']}\\n\\nGeneric ingredients: \"\"\"\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "# Print messages\n",
    "pprint(test_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T09:01:05.748590139Z",
     "start_time": "2023-08-24T09:01:05.280275484Z"
    }
   },
   "id": "4a917798eeadf76f"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spinach', 'mushrooms', 'onion', 'eggs', 'bacon', 'tomatoes', 'Ranch dressing']\n"
     ]
    }
   ],
   "source": [
    "# Let's extract ingredients from recipe description\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    messages=test_messages,\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T09:02:05.748590139Z",
     "start_time": "2023-08-24T09:02:05.280275484Z"
    }
   },
   "id": "b6b9bc5ad6545dbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
